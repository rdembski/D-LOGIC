{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D-LOGIC QUANT CORE v1.0\n",
    "## Professional Quantitative Analytics Engine for MetaTrader 5\n",
    "---\n",
    "**Author:** RafaB Dembski  \n",
    "**Architecture:** Google Colab + ngrok + Flask API  \n",
    "**Purpose:** Real-time quantitative analysis without external AI APIs\n",
    "\n",
    "### Features:\n",
    "- Statistical Analysis (Returns, Volatility, Correlations)\n",
    "- Risk Metrics (VaR, CVaR, Sharpe, Sortino, Calmar)\n",
    "- Regime Detection (Hidden Markov Model)\n",
    "- Monte Carlo Simulations\n",
    "- Probability Distributions\n",
    "- Pattern Recognition (ML-based)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1. INSTALLATION & SETUP {display-mode: \"form\"}\n",
    "#@markdown ### Install required packages and configure ngrok\n",
    "\n",
    "!pip install flask flask-cors pyngrok numpy pandas scipy scikit-learn hmmlearn --quiet\n",
    "\n",
    "print(\"[OK] All packages installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 2. NGROK AUTHENTICATION {display-mode: \"form\"}\n",
    "#@markdown ### Enter your ngrok authtoken (free at ngrok.com)\n",
    "\n",
    "NGROK_TOKEN = \"\"  #@param {type:\"string\"}\n",
    "\n",
    "from pyngrok import ngrok\n",
    "\n",
    "if NGROK_TOKEN:\n",
    "    ngrok.set_auth_token(NGROK_TOKEN)\n",
    "    print(\"[OK] ngrok authenticated\")\n",
    "else:\n",
    "    print(\"[!] No token provided - using free tier (limited)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3. QUANT CORE ENGINE {display-mode: \"form\"}\n",
    "#@markdown ### Core quantitative analysis module\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew, kurtosis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class QuantCore:\n",
    "    \"\"\"\n",
    "    Professional Quantitative Analysis Engine\n",
    "    Optimized for real-time trading decisions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.regime_model = None\n",
    "        self.anomaly_detector = IsolationForest(contamination=0.1, random_state=42)\n",
    "        \n",
    "    # ==================== STATISTICAL ANALYSIS ====================\n",
    "    \n",
    "    def calculate_returns(self, prices, method='log'):\n",
    "        \"\"\"Calculate returns from price series\"\"\"\n",
    "        prices = np.array(prices)\n",
    "        if method == 'log':\n",
    "            return np.diff(np.log(prices))\n",
    "        return np.diff(prices) / prices[:-1]\n",
    "    \n",
    "    def realized_volatility(self, returns, annualize=True):\n",
    "        \"\"\"Calculate realized volatility\"\"\"\n",
    "        vol = np.std(returns)\n",
    "        return vol * np.sqrt(252) if annualize else vol\n",
    "    \n",
    "    def rolling_volatility(self, returns, window=20):\n",
    "        \"\"\"Calculate rolling volatility\"\"\"\n",
    "        returns = np.array(returns)\n",
    "        if len(returns) < window:\n",
    "            return np.std(returns) * np.sqrt(252)\n",
    "        return np.std(returns[-window:]) * np.sqrt(252)\n",
    "    \n",
    "    def distribution_stats(self, returns):\n",
    "        \"\"\"Calculate distribution statistics\"\"\"\n",
    "        returns = np.array(returns)\n",
    "        return {\n",
    "            'mean': np.mean(returns),\n",
    "            'std': np.std(returns),\n",
    "            'skewness': skew(returns),\n",
    "            'kurtosis': kurtosis(returns),\n",
    "            'min': np.min(returns),\n",
    "            'max': np.max(returns)\n",
    "        }\n",
    "    \n",
    "    # ==================== RISK METRICS ====================\n",
    "    \n",
    "    def value_at_risk(self, returns, confidence=0.95, method='historical'):\n",
    "        \"\"\"Calculate Value at Risk\"\"\"\n",
    "        returns = np.array(returns)\n",
    "        if method == 'historical':\n",
    "            return np.percentile(returns, (1 - confidence) * 100)\n",
    "        elif method == 'parametric':\n",
    "            mu, sigma = np.mean(returns), np.std(returns)\n",
    "            return mu + sigma * norm.ppf(1 - confidence)\n",
    "        return np.percentile(returns, (1 - confidence) * 100)\n",
    "    \n",
    "    def expected_shortfall(self, returns, confidence=0.95):\n",
    "        \"\"\"Calculate Expected Shortfall (CVaR)\"\"\"\n",
    "        returns = np.array(returns)\n",
    "        var = self.value_at_risk(returns, confidence)\n",
    "        return np.mean(returns[returns <= var])\n",
    "    \n",
    "    def sharpe_ratio(self, returns, risk_free_rate=0.02):\n",
    "        \"\"\"Calculate Sharpe Ratio (annualized)\"\"\"\n",
    "        returns = np.array(returns)\n",
    "        excess_returns = returns - risk_free_rate / 252\n",
    "        if np.std(excess_returns) == 0:\n",
    "            return 0\n",
    "        return np.mean(excess_returns) / np.std(excess_returns) * np.sqrt(252)\n",
    "    \n",
    "    def sortino_ratio(self, returns, risk_free_rate=0.02):\n",
    "        \"\"\"Calculate Sortino Ratio (annualized)\"\"\"\n",
    "        returns = np.array(returns)\n",
    "        excess_returns = returns - risk_free_rate / 252\n",
    "        downside_returns = excess_returns[excess_returns < 0]\n",
    "        if len(downside_returns) == 0 or np.std(downside_returns) == 0:\n",
    "            return 0\n",
    "        return np.mean(excess_returns) / np.std(downside_returns) * np.sqrt(252)\n",
    "    \n",
    "    def max_drawdown(self, prices):\n",
    "        \"\"\"Calculate Maximum Drawdown\"\"\"\n",
    "        prices = np.array(prices)\n",
    "        peak = np.maximum.accumulate(prices)\n",
    "        drawdown = (prices - peak) / peak\n",
    "        return np.min(drawdown)\n",
    "    \n",
    "    def calmar_ratio(self, returns, prices):\n",
    "        \"\"\"Calculate Calmar Ratio\"\"\"\n",
    "        annual_return = np.mean(returns) * 252\n",
    "        mdd = abs(self.max_drawdown(prices))\n",
    "        return annual_return / mdd if mdd != 0 else 0\n",
    "    \n",
    "    # ==================== REGIME DETECTION ====================\n",
    "    \n",
    "    def detect_regime(self, returns, n_regimes=3):\n",
    "        \"\"\"\n",
    "        Detect market regime using K-Means clustering\n",
    "        Returns: 0=LOW_VOL, 1=NORMAL, 2=HIGH_VOL\n",
    "        \"\"\"\n",
    "        returns = np.array(returns).reshape(-1, 1)\n",
    "        if len(returns) < n_regimes * 2:\n",
    "            return 1, 0.5  # Default: NORMAL\n",
    "        \n",
    "        # Feature engineering\n",
    "        features = np.column_stack([\n",
    "            returns,\n",
    "            np.abs(returns),  # Magnitude\n",
    "        ])\n",
    "        \n",
    "        scaled = self.scaler.fit_transform(features)\n",
    "        kmeans = KMeans(n_clusters=n_regimes, random_state=42, n_init=10)\n",
    "        kmeans.fit(scaled)\n",
    "        \n",
    "        current_regime = kmeans.predict(scaled[-1:])[0]\n",
    "        \n",
    "        # Calculate confidence based on distance to cluster center\n",
    "        distances = kmeans.transform(scaled[-1:])[0]\n",
    "        confidence = 1 - (distances[current_regime] / np.sum(distances))\n",
    "        \n",
    "        return int(current_regime), float(confidence)\n",
    "    \n",
    "    def detect_trend_strength(self, prices, window=20):\n",
    "        \"\"\"\n",
    "        Calculate trend strength using linear regression R-squared\n",
    "        Returns: strength (0-1), direction (1=UP, -1=DOWN)\n",
    "        \"\"\"\n",
    "        prices = np.array(prices[-window:])\n",
    "        if len(prices) < 5:\n",
    "            return 0, 0\n",
    "        \n",
    "        x = np.arange(len(prices))\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(x, prices)\n",
    "        \n",
    "        strength = r_value ** 2  # R-squared\n",
    "        direction = 1 if slope > 0 else -1\n",
    "        \n",
    "        return float(strength), int(direction)\n",
    "    \n",
    "    # ==================== PROBABILITY ANALYSIS ====================\n",
    "    \n",
    "    def monte_carlo_simulation(self, returns, n_simulations=1000, n_days=5):\n",
    "        \"\"\"\n",
    "        Run Monte Carlo simulation for price prediction\n",
    "        Returns: probability of profit, expected return, VaR\n",
    "        \"\"\"\n",
    "        returns = np.array(returns)\n",
    "        mu = np.mean(returns)\n",
    "        sigma = np.std(returns)\n",
    "        \n",
    "        # Generate random paths\n",
    "        simulated_returns = np.random.normal(mu, sigma, (n_simulations, n_days))\n",
    "        cumulative_returns = np.sum(simulated_returns, axis=1)\n",
    "        \n",
    "        prob_profit = np.mean(cumulative_returns > 0)\n",
    "        expected_return = np.mean(cumulative_returns)\n",
    "        var_95 = np.percentile(cumulative_returns, 5)\n",
    "        \n",
    "        return {\n",
    "            'prob_profit': float(prob_profit),\n",
    "            'expected_return': float(expected_return),\n",
    "            'var_95': float(var_95),\n",
    "            'best_case': float(np.percentile(cumulative_returns, 95)),\n",
    "            'worst_case': float(np.percentile(cumulative_returns, 5))\n",
    "        }\n",
    "    \n",
    "    def calculate_probability_zones(self, prices, returns):\n",
    "        \"\"\"\n",
    "        Calculate probability zones based on distribution\n",
    "        \"\"\"\n",
    "        current_price = prices[-1]\n",
    "        daily_vol = np.std(returns)\n",
    "        \n",
    "        # 1 sigma zones (68% probability)\n",
    "        zone_1_up = current_price * (1 + daily_vol)\n",
    "        zone_1_down = current_price * (1 - daily_vol)\n",
    "        \n",
    "        # 2 sigma zones (95% probability)\n",
    "        zone_2_up = current_price * (1 + 2 * daily_vol)\n",
    "        zone_2_down = current_price * (1 - 2 * daily_vol)\n",
    "        \n",
    "        return {\n",
    "            'current': current_price,\n",
    "            'zone_1_up': zone_1_up,\n",
    "            'zone_1_down': zone_1_down,\n",
    "            'zone_2_up': zone_2_up,\n",
    "            'zone_2_down': zone_2_down,\n",
    "            'daily_vol_pct': daily_vol * 100\n",
    "        }\n",
    "    \n",
    "    # ==================== ANOMALY DETECTION ====================\n",
    "    \n",
    "    def detect_anomaly(self, returns):\n",
    "        \"\"\"\n",
    "        Detect market anomalies using Isolation Forest\n",
    "        Returns: is_anomaly (bool), anomaly_score (-1 to 1)\n",
    "        \"\"\"\n",
    "        returns = np.array(returns).reshape(-1, 1)\n",
    "        if len(returns) < 10:\n",
    "            return False, 0.0\n",
    "        \n",
    "        self.anomaly_detector.fit(returns)\n",
    "        score = self.anomaly_detector.decision_function(returns[-1:])[0]\n",
    "        prediction = self.anomaly_detector.predict(returns[-1:])[0]\n",
    "        \n",
    "        return prediction == -1, float(score)\n",
    "    \n",
    "    # ==================== MAIN ANALYSIS ====================\n",
    "    \n",
    "    def analyze(self, data):\n",
    "        \"\"\"\n",
    "        Main analysis function - processes market data and returns QUANT metrics\n",
    "        \n",
    "        Input data format:\n",
    "        {\n",
    "            'prices': [list of recent prices],\n",
    "            'h4_bias': 'BULLISH/BEARISH/NEUTRAL',\n",
    "            'h1_bias': 'BULLISH/BEARISH/NEUTRAL',\n",
    "            'zone': 'zone interaction string',\n",
    "            'liquidity': 'liquidity status',\n",
    "            'signals': 'entry signals'\n",
    "        }\n",
    "        \"\"\"\n",
    "        try:\n",
    "            prices = np.array(data.get('prices', []))\n",
    "            \n",
    "            if len(prices) < 20:\n",
    "                return self._default_response(\"INSUFFICIENT_DATA\")\n",
    "            \n",
    "            # Calculate returns\n",
    "            returns = self.calculate_returns(prices)\n",
    "            \n",
    "            # Risk metrics\n",
    "            var_95 = self.value_at_risk(returns, 0.95)\n",
    "            cvar = self.expected_shortfall(returns, 0.95)\n",
    "            sharpe = self.sharpe_ratio(returns)\n",
    "            sortino = self.sortino_ratio(returns)\n",
    "            mdd = self.max_drawdown(prices)\n",
    "            volatility = self.rolling_volatility(returns)\n",
    "            \n",
    "            # Regime detection\n",
    "            regime, regime_conf = self.detect_regime(returns)\n",
    "            regime_names = ['LOW_VOLATILITY', 'NORMAL', 'HIGH_VOLATILITY']\n",
    "            \n",
    "            # Trend analysis\n",
    "            trend_strength, trend_dir = self.detect_trend_strength(prices)\n",
    "            \n",
    "            # Monte Carlo\n",
    "            mc_result = self.monte_carlo_simulation(returns)\n",
    "            \n",
    "            # Anomaly detection\n",
    "            is_anomaly, anomaly_score = self.detect_anomaly(returns)\n",
    "            \n",
    "            # Distribution stats\n",
    "            dist_stats = self.distribution_stats(returns)\n",
    "            \n",
    "            # Generate trading decision\n",
    "            decision, confidence, comment = self._generate_decision(\n",
    "                data, sharpe, sortino, var_95, regime, trend_strength, \n",
    "                trend_dir, mc_result, is_anomaly, volatility\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                'decision': decision,\n",
    "                'confidence': confidence,\n",
    "                'comment': comment,\n",
    "                \n",
    "                # Risk Metrics\n",
    "                'var_95': round(var_95 * 10000, 2),  # in pips\n",
    "                'cvar': round(cvar * 10000, 2),\n",
    "                'sharpe': round(sharpe, 2),\n",
    "                'sortino': round(sortino, 2),\n",
    "                'max_dd': round(mdd * 100, 2),\n",
    "                'volatility': round(volatility * 100, 2),\n",
    "                \n",
    "                # Regime\n",
    "                'regime': regime_names[regime],\n",
    "                'regime_conf': round(regime_conf * 100, 0),\n",
    "                \n",
    "                # Trend\n",
    "                'trend_strength': round(trend_strength * 100, 0),\n",
    "                'trend_dir': 'UP' if trend_dir == 1 else 'DOWN',\n",
    "                \n",
    "                # Probability\n",
    "                'prob_profit': round(mc_result['prob_profit'] * 100, 0),\n",
    "                'expected_ret': round(mc_result['expected_return'] * 10000, 2),\n",
    "                \n",
    "                # Anomaly\n",
    "                'is_anomaly': is_anomaly,\n",
    "                'anomaly_score': round(anomaly_score, 2),\n",
    "                \n",
    "                # Distribution\n",
    "                'skewness': round(dist_stats['skewness'], 2),\n",
    "                'kurtosis': round(dist_stats['kurtosis'], 2)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return self._default_response(f\"ERROR: {str(e)}\")\n",
    "    \n",
    "    def _generate_decision(self, data, sharpe, sortino, var, regime, \n",
    "                           trend_str, trend_dir, mc, is_anomaly, vol):\n",
    "        \"\"\"\n",
    "        Generate trading decision based on quant metrics\n",
    "        \"\"\"\n",
    "        h4 = data.get('h4_bias', 'NEUTRAL')\n",
    "        h1 = data.get('h1_bias', 'NEUTRAL')\n",
    "        zone = data.get('zone', '')\n",
    "        \n",
    "        score = 0\n",
    "        reasons = []\n",
    "        \n",
    "        # 1. Risk-adjusted returns\n",
    "        if sharpe > 1.5:\n",
    "            score += 20\n",
    "            reasons.append(\"Strong Sharpe\")\n",
    "        elif sharpe > 0.5:\n",
    "            score += 10\n",
    "        elif sharpe < 0:\n",
    "            score -= 15\n",
    "            reasons.append(\"Negative Sharpe\")\n",
    "        \n",
    "        # 2. Regime analysis\n",
    "        if regime == 0:  # Low volatility\n",
    "            score += 15\n",
    "            reasons.append(\"Low Vol regime\")\n",
    "        elif regime == 2:  # High volatility\n",
    "            score -= 10\n",
    "            reasons.append(\"High Vol regime\")\n",
    "        \n",
    "        # 3. Trend alignment\n",
    "        bias_aligned = (h4 == h1 and h4 != 'NEUTRAL')\n",
    "        if bias_aligned:\n",
    "            score += 15\n",
    "            if trend_str > 0.6:\n",
    "                score += 10\n",
    "                reasons.append(\"Strong aligned trend\")\n",
    "        else:\n",
    "            reasons.append(\"Mixed structure\")\n",
    "        \n",
    "        # 4. Monte Carlo probability\n",
    "        if mc['prob_profit'] > 0.6:\n",
    "            score += 15\n",
    "            reasons.append(f\"{int(mc['prob_profit']*100)}% profit prob\")\n",
    "        elif mc['prob_profit'] < 0.4:\n",
    "            score -= 15\n",
    "        \n",
    "        # 5. Zone interaction\n",
    "        if 'INSIDE' in zone:\n",
    "            score += 10\n",
    "            reasons.append(\"In POI zone\")\n",
    "        \n",
    "        # 6. Anomaly check\n",
    "        if is_anomaly:\n",
    "            score -= 20\n",
    "            reasons.append(\"ANOMALY detected\")\n",
    "        \n",
    "        # 7. VaR check\n",
    "        if abs(var) > 0.02:  # More than 2% daily VaR\n",
    "            score -= 10\n",
    "            reasons.append(\"High VaR\")\n",
    "        \n",
    "        # Calculate confidence\n",
    "        confidence = min(max(50 + score, 0), 100)\n",
    "        \n",
    "        # Generate decision\n",
    "        if is_anomaly:\n",
    "            decision = 'DANGER'\n",
    "        elif score >= 30:\n",
    "            decision = 'EXECUTE'\n",
    "        elif score >= 0:\n",
    "            decision = 'WAIT'\n",
    "        else:\n",
    "            decision = 'DANGER'\n",
    "        \n",
    "        # Build comment\n",
    "        comment = ' | '.join(reasons[:3]) if reasons else 'Standard conditions'\n",
    "        \n",
    "        return decision, confidence, comment\n",
    "    \n",
    "    def _default_response(self, reason):\n",
    "        return {\n",
    "            'decision': 'WAIT',\n",
    "            'confidence': 0,\n",
    "            'comment': reason,\n",
    "            'var_95': 0, 'cvar': 0, 'sharpe': 0, 'sortino': 0,\n",
    "            'max_dd': 0, 'volatility': 0, 'regime': 'UNKNOWN',\n",
    "            'regime_conf': 0, 'trend_strength': 0, 'trend_dir': 'NONE',\n",
    "            'prob_profit': 50, 'expected_ret': 0, 'is_anomaly': False,\n",
    "            'anomaly_score': 0, 'skewness': 0, 'kurtosis': 0\n",
    "        }\n",
    "\n",
    "# Initialize engine\n",
    "quant_engine = QuantCore()\n",
    "print(\"[OK] QuantCore Engine initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4. FLASK API SERVER {display-mode: \"form\"}\n",
    "#@markdown ### Start the API server with ngrok tunnel\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import threading\n",
    "import json\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# Request counter for monitoring\n",
    "request_count = {'total': 0, 'success': 0, 'error': 0}\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return jsonify({\n",
    "        'status': 'OK',\n",
    "        'engine': 'D-LOGIC QUANT CORE v1.0',\n",
    "        'requests': request_count\n",
    "    })\n",
    "\n",
    "@app.route('/analyze', methods=['POST'])\n",
    "def analyze():\n",
    "    \"\"\"Main analysis endpoint\"\"\"\n",
    "    request_count['total'] += 1\n",
    "    \n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        \n",
    "        if not data:\n",
    "            request_count['error'] += 1\n",
    "            return jsonify({'error': 'No data provided'}), 400\n",
    "        \n",
    "        # Run analysis\n",
    "        result = quant_engine.analyze(data)\n",
    "        \n",
    "        request_count['success'] += 1\n",
    "        return jsonify(result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        request_count['error'] += 1\n",
    "        return jsonify({\n",
    "            'decision': 'WAIT',\n",
    "            'confidence': 0,\n",
    "            'comment': f'Server error: {str(e)}'\n",
    "        }), 500\n",
    "\n",
    "@app.route('/metrics', methods=['POST'])\n",
    "def metrics_only():\n",
    "    \"\"\"Get only risk metrics without decision\"\"\"\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        prices = data.get('prices', [])\n",
    "        \n",
    "        if len(prices) < 20:\n",
    "            return jsonify({'error': 'Need at least 20 price points'}), 400\n",
    "        \n",
    "        returns = quant_engine.calculate_returns(prices)\n",
    "        \n",
    "        return jsonify({\n",
    "            'var_95': round(quant_engine.value_at_risk(returns) * 10000, 2),\n",
    "            'sharpe': round(quant_engine.sharpe_ratio(returns), 2),\n",
    "            'sortino': round(quant_engine.sortino_ratio(returns), 2),\n",
    "            'volatility': round(quant_engine.rolling_volatility(returns) * 100, 2),\n",
    "            'max_dd': round(quant_engine.max_drawdown(prices) * 100, 2)\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "print(\"[OK] Flask API configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 5. START SERVER {display-mode: \"form\"}\n",
    "#@markdown ### Launch the server and get your public URL\n",
    "#@markdown **Copy the ngrok URL and paste it into MT5 settings!**\n",
    "\n",
    "import time\n",
    "\n",
    "# Start ngrok tunnel\n",
    "public_url = ngrok.connect(5000)\n",
    "print(\"=\"*60)\n",
    "print(\"D-LOGIC QUANT CORE SERVER\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n[PUBLIC URL]: {public_url}\")\n",
    "print(f\"\\n[ENDPOINT]:   {public_url}/analyze\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Copy the URL above and paste into MT5!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Run Flask in a thread\n",
    "def run_flask():\n",
    "    app.run(port=5000, debug=False, use_reloader=False)\n",
    "\n",
    "flask_thread = threading.Thread(target=run_flask)\n",
    "flask_thread.daemon = True\n",
    "flask_thread.start()\n",
    "\n",
    "print(\"\\n[OK] Server is running! Keep this notebook open.\")\n",
    "print(\"[INFO] Press STOP to terminate the server.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 6. TEST THE ENGINE (Optional) {display-mode: \"form\"}\n",
    "#@markdown ### Test the analysis with sample data\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Generate sample price data (simulating EURUSD)\n",
    "np.random.seed(42)\n",
    "base_price = 1.0850\n",
    "returns = np.random.normal(0.0001, 0.005, 100)\n",
    "prices = [base_price]\n",
    "for r in returns:\n",
    "    prices.append(prices[-1] * (1 + r))\n",
    "\n",
    "# Test data\n",
    "test_data = {\n",
    "    'prices': prices,\n",
    "    'h4_bias': 'BULLISH',\n",
    "    'h1_bias': 'BULLISH',\n",
    "    'zone': 'INSIDE FVG (Buy)',\n",
    "    'liquidity': 'PDH=50pts PDL=80pts',\n",
    "    'signals': 'CISD:BULL TRTL:NONE'\n",
    "}\n",
    "\n",
    "# Run analysis\n",
    "result = quant_engine.analyze(test_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"QUANT ANALYSIS RESULT\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nDecision:    {result['decision']}\")\n",
    "print(f\"Confidence:  {result['confidence']}%\")\n",
    "print(f\"Comment:     {result['comment']}\")\n",
    "print(\"\\n--- RISK METRICS ---\")\n",
    "print(f\"VaR (95%):   {result['var_95']} pips\")\n",
    "print(f\"CVaR:        {result['cvar']} pips\")\n",
    "print(f\"Sharpe:      {result['sharpe']}\")\n",
    "print(f\"Sortino:     {result['sortino']}\")\n",
    "print(f\"Max DD:      {result['max_dd']}%\")\n",
    "print(f\"Volatility:  {result['volatility']}%\")\n",
    "print(\"\\n--- REGIME ---\")\n",
    "print(f\"Regime:      {result['regime']}\")\n",
    "print(f\"Confidence:  {result['regime_conf']}%\")\n",
    "print(\"\\n--- TREND ---\")\n",
    "print(f\"Strength:    {result['trend_strength']}%\")\n",
    "print(f\"Direction:   {result['trend_dir']}\")\n",
    "print(\"\\n--- PROBABILITY ---\")\n",
    "print(f\"Prob Profit: {result['prob_profit']}%\")\n",
    "print(f\"Expected:    {result['expected_ret']} pips\")\n",
    "print(\"\\n--- DISTRIBUTION ---\")\n",
    "print(f\"Skewness:    {result['skewness']}\")\n",
    "print(f\"Kurtosis:    {result['kurtosis']}\")\n",
    "print(f\"Anomaly:     {result['is_anomaly']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 7. MONITOR REQUESTS {display-mode: \"form\"}\n",
    "#@markdown ### Monitor incoming requests from MT5\n",
    "\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "print(\"Monitoring requests... (refresh every 5 seconds)\")\n",
    "print(\"Press STOP to exit monitoring.\\n\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        clear_output(wait=True)\n",
    "        print(\"=\"*40)\n",
    "        print(\"D-LOGIC QUANT CORE - REQUEST MONITOR\")\n",
    "        print(\"=\"*40)\n",
    "        print(f\"\\nTotal Requests:  {request_count['total']}\")\n",
    "        print(f\"Successful:      {request_count['success']}\")\n",
    "        print(f\"Errors:          {request_count['error']}\")\n",
    "        print(f\"\\nServer Status:   ONLINE\")\n",
    "        print(f\"Timestamp:       {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        time.sleep(5)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nMonitoring stopped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
